# Лабораторная работа №2: Docker Compose

Реализация многокомпонентного приложения на основе Apache Spark с использованием Docker Compose.

##  Архитектура

Проект включает 5 сервисов, объединённых в единую сеть:

1. init
`init-wait` - Одноразовый сервис, ожидающий готовности PostgreSQL
2. app(4 сервиса)
`spark-master` - Spark Master — управляет кластером, UI на порту 8080 
`spark-worker` - Spark Worker — исполняет задачи, подключается к Master 
`spark-postgres` - PostgreSQL — база данных для хранения метаданных (в будущем) 
`spark-jupyter`  - Jupyter Notebook с PySpark — интерактивная среда для анализа 


## Описание docker-compose.yml

Файл `docker-compose.yml` описывает композицию из сервисов, объединённых в единую пользовательскую сеть `spark-network`:

1. **`init-wait`** — одноразовый init-контейнер на базе `alpine:latest`.  
   Ждёт готовности PostgreSQL через `healthcheck` и завершается.  
   Используется для гарантии, что app-сервисы запускаются только после полной инициализации зависимостей.

2. **`spark-master`** — основной сервис Apache Spark (Master).  
   - Собирается из локального `./spark/Dockerfile`.  
   - Имеет жёсткое имя контейнера: `spark-master`.  
   - Пробрасывает порты: `8080` (веб-интерфейс) и `7077` (RPC для воркеров).  
   - Использует volume `spark-data` для хранения рабочих файлов.  
   - Команда запуска переопределена через `command` для указания хоста и портов.

3. **`spark-worker`** — исполнительный узел Spark.  
   - Использует тот же образ, что и Master (`./spark/Dockerfile`).  
   - Имеет имя контейнера: `spark-worker`.  
   - Подключается к `spark-master` по внутреннему DNS-имени.  
   - Параметры (ядра, память) задаются через переменные из `.env`.

4. **`spark-postgres`** — СУБД PostgreSQL 15.  
   - Использует официальный образ `postgres:15`.  
   - Имя контейнера: `spark-postgres`.  
   - Хранит данные в volume `postgres-data`.  
   - Имеет `healthcheck` для корректной работы `init-wait`.  
   - Пробрасывает порт `5432` на хост.

5. **`jupyter-notebook`** — интерактивная среда на базе `jupyter/pyspark-notebook`.  
   - Собирается из `./jupyter/Dockerfile`.  
   - Имя контейнера: `spark-jupyter`.  
   - Пробрасывает порт `8888` с токеном из `.env`.  
   - Использует volume `jupyter-data` для сохранения ноутбуков.

Все переменные окружения вынесены в файл `.env`.  

---

## Ответы на вопросы

### 1. Можно ли ограничивать ресурсы (например, память или CPU) для сервисов в docker-compose.yml? Если нет, то почему, если да, то как?

Да, в docker-compose.yml можно ограничивать ресурсы (память, CPU) для отдельных сервисов. 
Ограничения задаются в секции deploy.resources для новых версий (limits для максимумов, reservations для минимумов) или напрямую через cpus и mem_limit в старых версиях. Эти параметры работают при запуске через docker-compose up и предотвращают перегрузку хоста одним контейнером.

### 2. Как можно запустить только определенный сервис из docker-compose.yml, не запуская остальные?

Это делается с помощью команды docker-compose up имя_сервиса, которая поднимает указанный сервис и его зависимости.