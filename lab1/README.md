# Лабораторная работа №1: Dockerfile Best Practices

## Описание
В данной работе реализованы два Dockerfile для Apache Spark:
- `Dockerfile.bad` — содержит плохие практики, но корректно запускается.
- `Dockerfile.good` — исправленные версии с учётом best practices.

---

## Плохие практики в `Dockerfile.bad` и их исправление

### 1. Использование тега `latest`
- **Проблема**: `FROM ubuntu:latest` может привести к непредсказуемым сборкам, так как образ может измениться со временем.
- **Исправление**: Использован конкретный образ `eclipse-temurin:11-jre-focal`.

### 2. Объединение нескольких операций в один `RUN`
- **Проблема**: Установка пакетов, скачивание и распаковка Spark в одной инструкции нарушает кеширование слоёв Docker.
- **Исправление**: Каждая логическая операция выделена, кэш используется эффективно

### 3. Запуск от root-пользователя
- **Проблема**: Повышает риски безопасности — любой exploit может получить полный доступ к хосту.
- **Исправление**: Создан непривилегированный пользователь `spark`, и приложение запускается от него.

---

## Две плохие практики по использованию контейнеров

1. **Хранение состояния внутри контейнера без volumes**  
   Сохранение данных внутри образа приведёт к их потере при перезапуске.  

2. **Запуск нескольких процессов в одном контейнере**  
   Запуск в одном контейнере нарушает принцип **один контейнер — один процесс**. Это усложняет масштабирование, мониторинг и отладку.  



## Когда не стоит использовать контейнеры

1. **Разработка ядра Linux или низкоуровневых систем**  
   КDocker работает поверх ядра хоста. Поэтому нельзя обновить или изменить ядро внутри контейнера, а также тестировать системные вызовы или драйверы ядра.

2. **Системы с жёсткими требованиями к безопасности**  
   Контейнеры изолируют на уровне ядра (namespaces, cgroups), но не предоставляют полной изоляции, как виртуальные машины.

---

## Сборка и запуск

### Плохой образ
```
docker build -t spark-bad -f Dockerfile.bad .
docker run -d -p 7077:7077 -p 8080:8080 -v $(pwd)/work:/opt/spark/work-dir spark-bad
```

### Хороший образ
```
docker build -t spark-good -f Dockerfile.good .
docker run -d -p 7077:7077 -p 8080:8080 -v $(pwd)/work:/opt/spark/work-dir spark-good
```